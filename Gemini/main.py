import google.generativeai as genai
import json
from GEMINI_KEY import GEMINI_API_KEY

# Configura a API key
API_KEY = GEMINI_API_KEY
genai.configure(api_key=API_KEY)

# Define o modelo do Gemini
model = genai.GenerativeModel("gemini-2.0-flash")

# Carrega hist√≥rico de conversa com tratamento de erros
def load_history():
    try:
        with open("chat_history.json", "r") as file:
            return json.load(file)
    except (FileNotFoundError, json.JSONDecodeError):
        return []

# Salva o hist√≥rico atualizado
def save_history(history):
    with open("chat_history.json", "w") as file:
        json.dump(history, file, indent=4)

# Carrega treinamento salvo com tratamento de erros
def load_training():
    try:
        with open("training_data.json", "r") as file:
            return json.load(file).get("content", "")
    except (FileNotFoundError, json.JSONDecodeError):
        return ""

# Salva treinamento em arquivo separado
def save_training(training_text):
    with open("training_data.json", "w") as file:
        json.dump({"content": training_text}, file, indent=4)

# Adiciona novo contexto ao existente
def add_training(new_context):
    existing_context = load_training()
    updated_context = existing_context + "\n" + new_context if existing_context else new_context
    save_training(updated_context)
    return updated_context

# Converte o hist√≥rico para o formato aceito pelo Gemini
# O contexto agora √© parte de cada mensagem do usu√°rio
def format_history_for_gemini(history, training_context):
    formatted_history = []
    for msg in history:
        if msg["role"] == "user" and training_context:
            msg["content"] = f"Contexto: {training_context}\n{msg['content']}"
        formatted_history.append({"role": msg["role"], "parts": [{"text": msg["content"]}]})
    return formatted_history

# Inicializa hist√≥rico e carrega treinamento
chat_history = load_history()
training_context = load_training()

print("ü§ñ Chat Gemini (digite 'sair' para encerrar, 'treinar' para ensinar o bot, 'adicionar treino' para expandir o treinamento, 'resetar treino' para apagar o treinamento)")

while True:
    user_message = input("Voc√™: ")

    if user_message.lower() == "sair":
        print("Encerrando conversa. Hist√≥rico salvo!")
        save_history(chat_history)
        break

    # MODO TREINAMENTO
    if user_message.lower() == "treinar":
        print("üß† Modo treinamento ativado! Digite as informa√ß√µes para o bot aprender (digite 'fim' para terminar).")
        training_data = []
        while True:
            info = input("Treine o bot: ")
            if info.lower() == "fim":
                break
            training_data.append(info)

        # Salva o novo treinamento
        training_context = " ".join(training_data)
        save_training(training_context)
        print("‚úÖ Treinamento salvo! Agora o bot usar√° esse contexto.")
        continue

    # Adicionar mais contexto ao treinamento
    if user_message.lower() == "adicionar treino":
        print("‚ûï Adicionar mais contexto ao treinamento. Digite o novo conte√∫do (digite 'fim' para terminar):")
        new_training_data = []
        while True:
            info = input("Novo treinamento: ")
            if info.lower() == "fim":
                break
            new_training_data.append(info)

        # Adiciona o novo contexto ao existente
        training_context = add_training(" ".join(new_training_data))
        print("‚úÖ Novo contexto adicionado ao treinamento!")
        continue

    # Resetar o treinamento
    if user_message.lower() == "resetar treino":
        save_training("")
        training_context = ""
        print("üîÑ Treinamento resetado. O bot agora n√£o tem contexto especializado.")
        continue

    # Adiciona a mensagem do usu√°rio ao hist√≥rico
    chat_history.append({"role": "user", "content": user_message})

    # Prepara o hist√≥rico no formato correto para o Gemini
    formatted_history = format_history_for_gemini(chat_history, training_context)

    # Gera a resposta usando o hist√≥rico formatado
    try:
        response = model.generate_content(formatted_history)
        bot_reply = response.text
    except Exception as e:
        bot_reply = "Desculpe, houve um erro ao processar a resposta. Tente novamente."
        print(f"Erro: {e}")

    print(f"Gemini: {bot_reply}\n")

    # Salva a resposta no hist√≥rico
    chat_history.append({"role": "assistant", "content": bot_reply})

    # Atualiza o hist√≥rico no arquivo
    save_history(chat_history)

# Adiciona o novo formato de an√°lise Business Model Canvas ao treinamento
canvas_training_data = "O chatbot agora √© um agente especializado na an√°lise de Business Model Canvas. Ele identifica falhas conceituais, aponta inconsist√™ncias e sugere melhorias estrat√©gicas. A an√°lise √© organizada por t√≥picos: Proposta de Valor, Segmentos de Mercado, Canais, Rela√ß√£o com o Cliente, Fontes de Renda, Recursos-chave, Atividades-chave, Parceiros-chave, Estrutura de Custos e Conclus√£o e Recomenda√ß√µes. As respostas s√£o objetivas, estruturadas e fornecem exemplos pr√°ticos, quando aplic√°vel. Al√©m disso, ele gera relat√≥rios em PDF com cabe√ßalho e rodap√© personalizados."
add_training(canvas_training_data)